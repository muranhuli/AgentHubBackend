import uuid
import re
from coper.LLM import LLM
from coper.basic_ops import Mul
from core.Context import Context
from coper.Service import Service
import logging
from AGENT.unit.pydantic_models import CounterExampleOutput
log_filename = f"judge_error_type.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)
SUBMISSION_LANGUAGE = "C++14"
def generate_counter_example(problem_desc: str, student_code: str, error_analysis: dict, llm_model: str) -> str:
    """
    å½“ LLM åˆ¤æ–­ä¸ºæ¦‚å¿µæ€§é”™è¯¯æ—¶ï¼Œä½¿ç”¨ LLM ç”Ÿæˆä¸€ä¸ªèƒ½æš´éœ²æ­¤æ¦‚å¿µæ€§é”™è¯¯çš„æµ‹è¯•ç”¨ä¾‹ï¼ˆåä¾‹ï¼‰ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«è¾“å…¥å’Œæ­£ç¡®è¾“å‡ºçš„å­—ç¬¦ä¸²ã€‚
    """
    logging.info("ğŸ¤– LLM: æ­£åœ¨ä¸ºæ¦‚å¿µæ€§é”™è¯¯ç”Ÿæˆåä¾‹...")
    
    # æ„å»ºç»™ LLM çš„ Promptï¼Œå¼ºè°ƒä»»åŠ¡å’Œä¸Šä¸‹æ–‡
    base_prompt = f"""
[SYSTEM]
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ç«èµ›ç¼–ç¨‹å¯¼å¸ˆã€‚å­¦ç”Ÿçš„ä»£ç å› æ ¸å¿ƒé€»è¾‘å­˜åœ¨æ¦‚å¿µæ€§ç¼ºé™·è€Œè¢«åˆ¤é”™è¯¯ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æä¾›ä¸€ä¸ªå…·ä½“çš„è¾“å…¥ï¼Œç”¨ä»¥å±•ç¤ºè¿™ä¸ªé€»è¾‘ç¼ºé™·ï¼Œå¹¶ç»™å‡ºè¯¥è¾“å…¥çš„æ­£ç¡®è¾“å‡ºã€‚

[é—®é¢˜é™ˆè¿°]
{problem_desc}

[å­¦ç”Ÿä»£ç ]
```{SUBMISSION_LANGUAGE.lower()}
{student_code}
[LLM å¯¹æ¦‚å¿µæ€§é”™è¯¯çš„åˆ†æ]
LLM å…ˆå‰å·²å°†é”™è¯¯ç±»å‹åˆ¤æ–­ä¸ºæ¦‚å¿µæ€§ï¼ŒåŸå› ä¸ºï¼š
{error_analysis.get('reasoning', 'æœªæä¾›åŸå› ã€‚')}
[ä»»åŠ¡]
åŸºäºé—®é¢˜é™ˆè¿°å’Œå·²è¯†åˆ«å‡ºçš„æ¦‚å¿µæ€§é”™è¯¯ï¼Œè®¾è®¡ä¸€ä¸ªç‰¹å®šçš„è¾“å…¥æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶ç¡®å®šè¯¥è¾“å…¥å¯¹åº”çš„æ­£ç¡®è¾“å‡ºã€‚
"""
    structured_prompt = base_prompt + """
    [è¾“å‡ºè¦æ±‚]
ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªåªåŒ…å« input_data å’Œ expected_output é”®çš„ JSON å¯¹è±¡ã€‚
"""
    natural_prompt = base_prompt + """
    [è¾“å‡ºæ ¼å¼]
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–æ–‡å­—ï¼š
è¾“å…¥:
<ä½ ç”Ÿæˆçš„è¾“å…¥>
æ­£ç¡®è¾“å‡º:
<ä½ ç”Ÿæˆçš„è¾“å…¥å¯¹åº”çš„æ­£ç¡®è¾“å‡º>
"""
    try:
        llm = LLM(model=llm_model)
        generated_input = None
        correct_output = None

        # === ä¸»æ¨¡å¼ï¼šå°è¯•ç»“æ„åŒ–è¾“å‡º ===
        try:
            response = llm(structured_prompt, structured_output=CounterExampleOutput.model_json_schema()).result()
            structured_data = response.get("structured_output")

            if structured_data and "input_data" in structured_data and "expected_output" in structured_data:
                generated_input = structured_data.get("input_data")
                correct_output = structured_data.get("expected_output")
                logging.info("âœ… AI å·²é€šè¿‡ç»“æ„åŒ–è¾“å‡ºç”Ÿæˆåä¾‹ã€‚")

        except Exception as e:
            logging.warning(f"ç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}, å°†å°è¯•è‡ªç„¶è¯­è¨€è§£ææ–¹å¼...")

        # === å¤‡ç”¨æ¨¡å¼ï¼šå¦‚æœä¸»æ¨¡å¼å¤±è´¥ï¼Œåˆ™å°è¯•è‡ªç„¶è¯­è¨€è§£æ ===
        if generated_input is None or correct_output is None:
            response = llm(natural_prompt).result()
            content = response.get("content", "")
            logging.debug(f"AI è‡ªç„¶è¯­è¨€å“åº”å†…å®¹:\n{content}")

            input_match = re.search(r"è¾“å…¥:\s*\n?(.*?)æ­£ç¡®è¾“å‡º:", content, re.DOTALL | re.IGNORECASE)
            output_match = re.search(r"æ­£ç¡®è¾“å‡º:\s*\n?(.*)", content, re.DOTALL | re.IGNORECASE)
            
            if input_match and output_match:
                generated_input = input_match.group(1).strip()
                correct_output = output_match.group(1).strip()
                logging.info("âœ… AI å·²é€šè¿‡è‡ªç„¶è¯­è¨€è§£æç”Ÿæˆåä¾‹ã€‚")
        
        # --- æ„å»ºå¹¶è¿”å›æœ€ç»ˆç»“æœ ---
        if generated_input and correct_output:
            counter_example_info = f"LLM ç”Ÿæˆçš„åä¾‹:\nè¾“å…¥:\n{generated_input}\n\næ­£ç¡®è¾“å‡º:\n{correct_output}\n"
            logging.info(counter_example_info)
            return counter_example_info
        else:
            logging.error("âŒ ä¸¤ç§æ–¹å¼å‡æœªèƒ½æˆåŠŸç”Ÿæˆåä¾‹ã€‚")
            return "LLMæœªèƒ½æˆåŠŸç”Ÿæˆåä¾‹ã€‚"

    except Exception as e:
        logging.error(f"âŒ ä½¿ç”¨ LLM ç”Ÿæˆåä¾‹æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        logging.error(traceback.format_exc())
        return f"LLM åœ¨ç”Ÿæˆåä¾‹æ—¶å‡ºé”™: {e}"