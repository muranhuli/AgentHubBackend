import uuid
import re
import traceback
from typing import List, Union
from coper.LLM import LLM
from coper.basic_ops import Mul
from core.Context import Context
from coper.Service import Service
import logging
from AGENT.unit.pydantic_models import TestCase, TestCaseList
log_filename = f"judge_error_type.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)
SUBMISSION_LANGUAGE = "C++14"
def generate_edge_cases(problem_desc, model_identifier: str) -> str:
    """
    ä½¿ç”¨ LLM æ ¹æ®é¢˜ç›®æè¿°ç”Ÿæˆæ½œåœ¨çš„è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹ã€‚
    è¿”å›æ ¼å¼åŒ–çš„è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹å­—ç¬¦ä¸²ã€‚
    """
    # import traceback  # æ·»åŠ å¿…è¦çš„å¯¼å…¥
    # import logging
    
    logging.info("ğŸ§ª LLM: æ­£åœ¨ç”Ÿæˆè¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹...")

    base_prompt = f"""
[SYSTEM]
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç«èµ›ç¼–ç¨‹å‡ºé¢˜äººå’Œæµ‹è¯•å‘˜ã€‚è¯·æ ¹æ®ç»™å®šçš„ç¼–ç¨‹é—®é¢˜ï¼Œç”Ÿæˆä¸€ç»„å…¨é¢çš„ã€å¯èƒ½æš´éœ²ç¨‹åºæ½œåœ¨ç¼ºé™·çš„**è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹**ã€‚

[é—®é¢˜æè¿°]
{problem_desc}
""" 
    structured_prompt = base_prompt + """
[ä»»åŠ¡]
è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼Œå¹¶å°†ç»“æœä»¥ä¸€ä¸ªåŒ…å« 'test_cases' åˆ—è¡¨çš„ JSON å¯¹è±¡æ ¼å¼è¾“å‡ºï¼š
1.  ä»”ç»†åˆ†æé—®é¢˜æè¿°ä¸­çš„æ¯ä¸€ä¸ªçº¦æŸæ¡ä»¶ã€‚
2.  æ„æ€èƒ½å¤Ÿè§¦åŠè¿™äº›è¾¹ç•Œæˆ–æç«¯æƒ…å†µçš„è¾“å…¥æ•°æ®ã€‚
3.  å¯¹äºæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œæä¾› `input_data`, `expected_output`, `description`, å’Œ `case_type` ('basic', 'boundary', 'edge')ã€‚
""" 
    natural_prompt = base_prompt + """
[ä»»åŠ¡]
è¯·ä»¥æ¸…æ™°çš„ Markdown æ ¼å¼åˆ—å‡ºè¿™äº›è¾¹ç¼˜ç”¨ä¾‹ã€‚å¯¹äºæ¯ä¸ªç”¨ä¾‹ï¼Œæä¾›ï¼š
- è¾“å…¥
- é¢„æœŸè¾“å‡º
- è®¾è®¡ç†ç”±

ç¤ºä¾‹ï¼š
## è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹
### ç”¨ä¾‹ 1: æœ€å°å€¼è¾¹ç•Œ
- **è¾“å…¥**: ...
- **é¢„æœŸè¾“å‡º**: ...
- **è®¾è®¡ç†ç”±**: ...
"""
    try:
        llm = LLM(model_identifier)

        # === ä¸»æ¨¡å¼ï¼šå°è¯•ç»“æ„åŒ–è¾“å‡º ===
        try:
            response = llm(structured_prompt, structured_output=TestCaseList.model_json_schema()).result()
            structured_data = response.get("structured_output")

            if structured_data and "test_cases" in structured_data and isinstance(structured_data["test_cases"], list):
                test_cases_dicts = structured_data.get("test_cases", [])
                test_cases = [TestCase(**case_dict) for case_dict in test_cases_dicts]
                logging.info(f"âœ… AI å·²é€šè¿‡ç»“æ„åŒ–è¾“å‡ºç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹ã€‚")
                return test_cases # ç›´æ¥è¿”å› TestCase å¯¹è±¡åˆ—è¡¨
        
        except Exception as e:
            logging.warning(f"ç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}, å°†å°è¯•è‡ªç„¶è¯­è¨€è§£ææ–¹å¼...")

        # === å¤‡ç”¨æ¨¡å¼ï¼šå¦‚æœä¸»æ¨¡å¼å¤±è´¥ï¼Œåˆ™è·å– Markdown å­—ç¬¦ä¸² ===
        logging.info("åˆ‡æ¢åˆ°è‡ªç„¶è¯­è¨€æ¨¡å¼ç”Ÿæˆè¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹...")
        response = llm(natural_prompt).result()
        content = response.get("content", "")
        logging.debug(f"LLM è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹ï¼ˆè‡ªç„¶è¯­è¨€ï¼‰å“åº”:\n{content}")
        
        edge_cases_content = content.strip()
        if not edge_cases_content.startswith("#"):
            edge_cases_content = f"# è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹\n\n{edge_cases_content}"
            
        logging.info("âœ… AI å·²é€šè¿‡è‡ªç„¶è¯­è¨€æ ¼å¼ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æŠ¥å‘Šã€‚")
        return edge_cases_content

    except Exception as e:
        logging.error(f"âŒ ç”Ÿæˆè¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        logging.error(traceback.format_exc())
        return "# è¾¹ç¼˜æµ‹è¯•ç”¨ä¾‹\n\nç”Ÿæˆå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ã€‚"
