import uuid
import re
from coper.LLM import LLM
from coper.basic_ops import Mul
from core.Context import Context
from coper.Service import Service
import traceback
import logging
from AGENT.unit.pydantic_models import PossibleErrorsOutput
log_filename = f"judge_error_type.log"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()  # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)
SUBMISSION_LANGUAGE = "C++14"
def generate_possible_errors(problem_desc, model_name: str) -> str:
    """
    ç”Ÿæˆé’ˆå¯¹ç‰¹å®šé¢˜ç›®å¯èƒ½å‡ºç°çš„é”™è¯¯ç±»å‹å’Œå…·ä½“æè¿°ã€‚
    
    :param problem_description: é¢˜ç›®æè¿°ï¼ˆç®€åŒ–æˆ–å®Œæ•´æè¿°ï¼‰
    :param model_name: ä½¿ç”¨çš„LLMæ¨¡å‹åç§°
    :return: é”™è¯¯æè¿°çš„Markdownæ–‡æœ¬
    """
    logging.info("ğŸ” LLM: æ­£åœ¨ç”Ÿæˆæ½œåœ¨é”™è¯¯åˆ†æ...")
    
    # æ„å»ºæç¤ºè¯
    base_prompt = f"""
[SYSTEM]
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç«èµ›ç¼–ç¨‹æ•™ç»ƒï¼Œè¯·åˆ†æç»™å®šç¼–ç¨‹é—®é¢˜ï¼ŒæŒ‡å‡ºè§£é¢˜è€…åœ¨ç”¨ {SUBMISSION_LANGUAGE} è§£å†³æ­¤é—®é¢˜æ—¶å¯èƒ½çŠ¯çš„å¸¸è§é”™è¯¯ç±»å‹åŠå…·ä½“åŸå› ã€‚

[é—®é¢˜æè¿°]
{problem_desc}
""" 
    structured_prompt = base_prompt + """
[ä»»åŠ¡]
è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼Œå¹¶å°†ç»“æœä»¥ Markdown æ ¼å¼å¡«å……åˆ°æŒ‡å®šçš„ JSON å­—æ®µ `markdown_content` ä¸­ï¼š
1. åˆ†æé¢˜ç›®ä¸­çš„ä¸»è¦éš¾ç‚¹å’Œé™·é˜±ã€‚
2. åˆ†ç±»åˆ—å‡ºå¯èƒ½çš„é”™è¯¯ç±»å‹ï¼ˆå¦‚æ¦‚å¿µæ€§é”™è¯¯ã€å®ç°æ€§é”™è¯¯ï¼‰ã€‚
3. ä¸ºæ¯ç§é”™è¯¯ç±»å‹æä¾›ç®€è¦çš„ç¤ºä¾‹ã€åŸå› è§£é‡Šå’Œé¿å…å»ºè®®ã€‚
"""
    natural_prompt = base_prompt + """
[ä»»åŠ¡]
è¯·ä»¥æ¸…æ™°çš„ Markdown æ ¼å¼è¾“å‡ºä½ çš„åˆ†ææŠ¥å‘Šï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. **ä¸»è¦éš¾ç‚¹ä¸é™·é˜±**
2. **æ¦‚å¿µæ€§é”™è¯¯** (å¦‚æœé€‚ç”¨)
3. **å®ç°æ€§é”™è¯¯** (å¦‚æœé€‚ç”¨)
   - é”™è¯¯1æè¿°
     - ç¤ºä¾‹ä»£ç /ä¼ªä»£ç 
     - åŸå› åˆ†æ
     - é¿å…å»ºè®®
"""
    try:
        llm = LLM(model_name)
        errors_content = None

        # === ä¸»æ¨¡å¼ï¼šå°è¯•ç»“æ„åŒ–è¾“å‡º ===
        try:
            response = llm(structured_prompt, structured_output=PossibleErrorsOutput.model_json_schema()).result()
            structured_data = response.get("structured_output")

            if structured_data and "markdown_content" in structured_data:
                errors_content = structured_data.get("markdown_content")
                logging.info("âœ… AI å·²é€šè¿‡ç»“æ„åŒ–è¾“å‡ºç”Ÿæˆæ½œåœ¨é”™è¯¯åˆ†æã€‚")
        
        except Exception as e:
            logging.warning(f"ç»“æ„åŒ–è¾“å‡ºå¤±è´¥: {e}, å°†å°è¯•è‡ªç„¶è¯­è¨€è§£ææ–¹å¼...")

        # === å¤‡ç”¨æ¨¡å¼ï¼šå¦‚æœä¸»æ¨¡å¼å¤±è´¥ï¼Œåˆ™è·å–è‡ªç„¶è¯­è¨€è¾“å‡º ===
        if not errors_content:
            response = llm(natural_prompt).result()
            content = response.get("content", "")
            logging.debug(f"LLM æ½œåœ¨é”™è¯¯åˆ†æï¼ˆè‡ªç„¶è¯­è¨€ï¼‰å“åº”:\n{content}")
            errors_content = content.strip()
            if errors_content:
                logging.info("âœ… AI å·²é€šè¿‡è‡ªç„¶è¯­è¨€æ ¼å¼ç”Ÿæˆæ½œåœ¨é”™è¯¯åˆ†æã€‚")
        
        # --- æ„å»ºå¹¶è¿”å›æœ€ç»ˆæŠ¥å‘Š ---
        if not errors_content:
            errors_content = "LLM æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„æ½œåœ¨é”™è¯¯åˆ†æã€‚"
        
        # ç¡®ä¿æŠ¥å‘Šæœ‰ä¸€ä¸ªç»Ÿä¸€çš„æ ‡é¢˜
        if not errors_content.strip().startswith("#"):
            errors_content = f"# æ½œåœ¨é”™è¯¯åˆ†æ\n\n{errors_content}"

        return errors_content

    except Exception as e:
        logging.error(f"âŒ ç”Ÿæˆæ½œåœ¨é”™è¯¯åˆ†ææ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        logging.error(traceback.format_exc())
        return "# æ½œåœ¨é”™è¯¯åˆ†æ\n\nç”Ÿæˆå¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆ†æé¢˜ç›®éš¾ç‚¹å’Œå¸¸è§é”™è¯¯ã€‚"